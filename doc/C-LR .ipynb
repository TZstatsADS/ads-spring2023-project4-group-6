{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc8d8586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load modules\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import log_loss\n",
    "import utils as ut\n",
    "import loss_funcs as lf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25d0a955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>race</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>two_year_recid</th>\n",
       "      <th>length_of_stay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>African-American</td>\n",
       "      <td>-0.733607</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.167773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>&lt; 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>0.055928</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.340654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>2.029767</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.244609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>-0.733607</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.321445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>&lt; 25</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>-0.536224</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.359864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sex  age_cat              race  priors_count c_charge_degree  \\\n",
       "0    Male  25 - 45  African-American     -0.733607               F   \n",
       "1    Male     < 25  African-American      0.055928               F   \n",
       "2    Male  25 - 45         Caucasian      2.029767               F   \n",
       "3  Female  25 - 45         Caucasian     -0.733607               M   \n",
       "4    Male     < 25         Caucasian     -0.536224               F   \n",
       "\n",
       "   two_year_recid  length_of_stay  \n",
       "0               1       -0.167773  \n",
       "1               1       -0.340654  \n",
       "2               1       -0.244609  \n",
       "3               0       -0.321445  \n",
       "4               1       -0.359864  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('../output/compas-scores-two-years_cleaned.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cc087b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>race</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>two_year_recid</th>\n",
       "      <th>length_of_stay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.733607</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.167773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.055928</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.340654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.029767</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.244609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.733607</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.321445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.536224</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.359864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sex  age_cat  race  priors_count  c_charge_degree  two_year_recid  \\\n",
       "0    1        1     0     -0.733607                1               1   \n",
       "1    1        0     0      0.055928                1               1   \n",
       "2    1        1     1      2.029767                1               1   \n",
       "3    0        1     1     -0.733607                0               0   \n",
       "4    1        0     1     -0.536224                1               1   \n",
       "\n",
       "   length_of_stay  \n",
       "0       -0.167773  \n",
       "1       -0.340654  \n",
       "2       -0.244609  \n",
       "3       -0.321445  \n",
       "4       -0.359864  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encoding to dummy variables\n",
    "df['sex'] = df['sex'].apply(lambda sex: 0 if sex == 'Female' else 1)\n",
    "df['age_cat'] = df['age_cat'].apply(lambda age_cat: 2 if age_cat == '> 45' else(1 if age_cat == '25 - 45' else 0))\n",
    "df['race'] = df['race'].apply(lambda race: 0 if race == 'African-American' else 1)\n",
    "df['c_charge_degree'] = df['c_charge_degree'].apply(lambda c_charge_degree: 0 if c_charge_degree == 'M' else 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ccfe044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex                0\n",
       "age_cat            0\n",
       "race               0\n",
       "priors_count       0\n",
       "c_charge_degree    0\n",
       "two_year_recid     0\n",
       "length_of_stay     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the mapping\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdc4cd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing features\n",
    "features = ['sex', 'age_cat', 'priors_count', 'c_charge_degree', 'length_of_stay']\n",
    "sensitive = 'race'\n",
    "target = 'two_year_recid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "615366c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process and shuffle data\n",
    "def preprocessing(df):\n",
    "    y_label = df[target]\n",
    "    protected_attribute = df[sensitive]\n",
    "    df_new = df[features]\n",
    "    y_label, protected_attribute, df_new = shuffle(y_label, protected_attribute, df_new, random_state = 704)\n",
    "    \n",
    "    return y_label.to_numpy(), protected_attribute.to_numpy(), df_new.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "316158f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test\n",
    "y_label, protected_attribute, df_new =  preprocessing(df)\n",
    "train_index = int(len(df_new) * 0.7)\n",
    "x_train, y_train, race_train = df_new[:train_index], y_label[:train_index], protected_attribute[:train_index]\n",
    "x_test, y_test, race_test = df_new[train_index:], y_label[train_index:],protected_attribute[train_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0c4b2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P-Rule function for evaluation\n",
    "def p_rule(sensitive_var, y_pred):\n",
    "    protected = np.where(sensitive_var == 1)[0]\n",
    "    not_protected = np.where(sensitive_var == 0)[0]\n",
    "    protected_pred = np.where(y_pred[protected] == 1)\n",
    "    not_protected_pred = np.where(y_pred[not_protected] == 1)\n",
    "    protected_percent = protected_pred[0].shape[0]/protected.shape[0]\n",
    "    not_protected_percent = not_protected_pred[0].shape[0]/not_protected.shape[0]\n",
    "    ratio = min(protected_percent/not_protected_percent, not_protected_percent/protected_percent)\n",
    "    \n",
    "    return ratio, protected_percent, not_protected_percent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e497de7",
   "metadata": {},
   "source": [
    "The \"80% rule\" (or the p%-rule) is a guideline established by the U.S. Equal Employment Opportunity Commission (EEOC) to help identify potential discrimination in hiring, promotion, or other employment decisions. It's a way to measure fairness and equal opportunity in these processes, particularly concerning sensitive attributes such as race, gender, age, or disability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03200ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibration function for evaluation\n",
    "def calibration(sensitive_var, y_pred, y_true):\n",
    "    protected_point = np.where(sensitive_var == 1)[0]\n",
    "    y_predcau = y_pred[protected_point]\n",
    "    y_truecau = y_true[protected_point]\n",
    "    pcau = sum(y_predcau==y_truecau)/len(y_truecau)\n",
    "    not_protected_point = np.where(sensitive_var == 0)[0]\n",
    "    y_predafa = y_pred[not_protected_point]\n",
    "    y_trueafa = y_true[not_protected_point]\n",
    "    pafa = sum(y_predafa==y_trueafa)/len(y_trueafa)\n",
    "    calibration = abs(pcau-pafa)\n",
    "    return(calibration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24daa53a",
   "metadata": {},
   "source": [
    "### Training Unconstrained Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01d5df3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Set</th>\n",
       "      <th>Accuracy (%)</th>\n",
       "      <th>P-rule (%)</th>\n",
       "      <th>Protected (%)</th>\n",
       "      <th>Not protected (%)</th>\n",
       "      <th>Calibration (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>Train</td>\n",
       "      <td>65.724638</td>\n",
       "      <td>57.224435</td>\n",
       "      <td>31.223881</td>\n",
       "      <td>54.563895</td>\n",
       "      <td>0.690624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR</td>\n",
       "      <td>Test</td>\n",
       "      <td>66.985915</td>\n",
       "      <td>53.653654</td>\n",
       "      <td>29.729730</td>\n",
       "      <td>55.410448</td>\n",
       "      <td>0.450097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classifier    Set  Accuracy (%)  P-rule (%)  Protected (%)  \\\n",
       "0         LR  Train     65.724638   57.224435      31.223881   \n",
       "1         LR   Test     66.985915   53.653654      29.729730   \n",
       "\n",
       "   Not protected (%)  Calibration (%)  \n",
       "0          54.563895         0.690624  \n",
       "1          55.410448         0.450097  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model and print results\n",
    "clf = LogisticRegression(random_state = 0).fit(x_train, y_train)\n",
    "coeff = clf.coef_\n",
    "intercept = clf.intercept_\n",
    "optimal_loss = log_loss(y_train, clf.predict_proba(x_train))\n",
    "results_lr = {\"Classifier\": [\"LR\", \"LR\"], \n",
    "              \"Set\": [\"Train\", \"Test\"],\n",
    "              \"Accuracy (%)\": [clf.score(x_train, y_train)*100, clf.score(x_test, y_test)*100],\n",
    "              \"P-rule (%)\": [p_rule(race_train, clf.predict(x_train))[0]*100, p_rule(race_test, clf.predict(x_test))[0]*100],\n",
    "              \"Protected (%)\": [p_rule(race_train, clf.predict(x_train))[1]*100, p_rule(race_test, clf.predict(x_test))[1]*100],\n",
    "              \"Not protected (%)\": [p_rule(race_train, clf.predict(x_train))[2]*100, p_rule(race_test, clf.predict(x_test))[2]*100],\n",
    "              \"Calibration (%)\": [calibration(race_train, clf.predict(x_train), y_train)*100, calibration(race_test, clf.predict(x_test), y_test)*100]}\n",
    "pd.DataFrame(results_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe8c7f9",
   "metadata": {},
   "source": [
    "P-rule%: This metric assesses fairness in the classifier with respect to the protected and non-protected groups. A value closer to 100% indicates better fairness. The rule of thumb is 80%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379f9005",
   "metadata": {},
   "source": [
    "Calibration: the difference in prediction accuracy between protected and unprotected groups. It measures how well the model's prediction align with the true outcomes. The difference indicates whether the model is calibrated similiarly for protected and unprotected groups. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec211259",
   "metadata": {},
   "source": [
    "Protected (%): The percentage of positive outcomes (e.g., being hired) in the protected group (Caucasians). This helps to understand how the classifier performs on the protected group. The ratio of the number of positive outcomes for Caucasians to the total number of Caucasians in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffe1d5c",
   "metadata": {},
   "source": [
    "Not protected (%): The percentage of positive outcomes in the non-protected group (African-American).  It is the ratio of the number of positive outcomes for African-Americans to the total number of African-Americans in the dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a80bcd",
   "metadata": {},
   "source": [
    "### Interpretation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fcb25e",
   "metadata": {},
   "source": [
    "The accuracy for the test data is higher (66.98%). Nonetheless, the p-rule for test and training data are less than 80% indicating there may be some bias in the classifier. In this case, the calibration values are 0.69% for the Train dataset and 0.45% for the Test dataset, indicating that the model has little differences in prediction accuracies for both groups. (TBC: What is the threshold?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f043db55",
   "metadata": {},
   "source": [
    "### To improve fairness, it might be necessary to investigate the cause of the lower p-rule ratio and consider adjusting the classifier or incorporating fairness-enhancing techniques\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a903a643",
   "metadata": {},
   "source": [
    "### Applying Fairness Contraints "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6ec084",
   "metadata": {},
   "source": [
    "The fairness constraint is set to achieve a 0 covariance between the sensitive feature (race) and the distance to the decision boundary. A 0 covariance means there is no correlation between the two variables, which helps promote fairness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f730e46",
   "metadata": {},
   "source": [
    "1. Train the model using constraints to extract model weights (cweight). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd91d74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Constrains\n",
    "#In this case, only fairness constraints are applied (apply_fairness_constraints = 1)\n",
    "# While accuracy constraint and separate constraint are not applied (both set to 0).\n",
    "fairness_constraint = 1 \n",
    "accuracy_constraint = 0\n",
    "separate_constraint = 0\n",
    "gamma = None\n",
    "sensitive_attrs = ['race']\n",
    "sensitive_attrs_to_cov_thresh = {'race': 0}\n",
    "x_control = {'race': race_train}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d26dd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training model with constraints\n",
    "np.random.seed(704)\n",
    "cweight = ut.train_model(x_train,\n",
    "                   y_train,\n",
    "                   x_control,\n",
    "                   lf._logistic_loss,\n",
    "                   fairness_constraint,\n",
    "                   accuracy_constraint,\n",
    "                   separate_constraint,\n",
    "                   sensitive_attrs,\n",
    "                   sensitive_attrs_to_cov_thresh,\n",
    "                   gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9cbe7d",
   "metadata": {},
   "source": [
    "2. Feed the model with trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39fd9cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feeding model with coefficients and weights\n",
    "m = LogisticRegression()\n",
    "m.coef_= cweight.reshape((1,-1))\n",
    "m.intercept_ = 0\n",
    "m.classes_ = np.array([0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87586406",
   "metadata": {},
   "source": [
    "3. Assess the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "afa75587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Set</th>\n",
       "      <th>Accuracy (%)</th>\n",
       "      <th>P-rule (%)</th>\n",
       "      <th>Protected (%)</th>\n",
       "      <th>Not protected (%)</th>\n",
       "      <th>Calibration (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C-LR</td>\n",
       "      <td>Train</td>\n",
       "      <td>47.946860</td>\n",
       "      <td>99.942529</td>\n",
       "      <td>99.820896</td>\n",
       "      <td>99.878296</td>\n",
       "      <td>11.642275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C-LR</td>\n",
       "      <td>Test</td>\n",
       "      <td>47.267606</td>\n",
       "      <td>99.950990</td>\n",
       "      <td>99.857752</td>\n",
       "      <td>99.906716</td>\n",
       "      <td>15.142593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classifier    Set  Accuracy (%)  P-rule (%)  Protected (%)  \\\n",
       "0       C-LR  Train     47.946860   99.942529      99.820896   \n",
       "1       C-LR   Test     47.267606   99.950990      99.857752   \n",
       "\n",
       "   Not protected (%)  Calibration (%)  \n",
       "0          99.878296        11.642275  \n",
       "1          99.906716        15.142593  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the results\n",
    "results_clr = {\"Classifier\": [\"C-LR\", \"C-LR\"],\n",
    "               \"Set\": [\"Train\", \"Test\"],\n",
    "               \"Accuracy (%)\": [m.score(x_train, y_train)*100, m.score(x_test, y_test)*100],\n",
    "               \"P-rule (%)\": [p_rule(race_train, m.predict(x_train))[0]*100, p_rule(race_test, m.predict(x_test))[0]*100],\n",
    "               \"Protected (%)\": [p_rule(race_train, m.predict(x_train))[1]*100, p_rule(race_test, m.predict(x_test))[1]*100],\n",
    "               \"Not protected (%)\": [p_rule(race_train, m.predict(x_train))[2]*100, p_rule(race_test, m.predict(x_test))[2]*100],\n",
    "               \"Calibration (%)\": [calibration(race_train, m.predict(x_train), y_train)*100, calibration(race_test, m.predict(x_test), y_test)*100]}\n",
    "pd.DataFrame(results_clr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d08067",
   "metadata": {},
   "source": [
    "### Interpretation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e712e21",
   "metadata": {},
   "source": [
    "The accuracy is lower compared to the based-model. Fairness wise, p-rule is drastically improved nearing 100% indicating the model is fair vis-a-vis to race. Meanwhile, the calibration is quite high compared to based-model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b54feca",
   "metadata": {},
   "source": [
    "### Tuning The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d3e5b2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fairness  Accuracy  Separation  Gamma            Set  \\\n",
      "0          0         0           0      1  [Train, Test]   \n",
      "1          0         0           0      2  [Train, Test]   \n",
      "2          0         0           0      3  [Train, Test]   \n",
      "3          0         0           0      4  [Train, Test]   \n",
      "4          0         0           0      5  [Train, Test]   \n",
      "5          0         0           0      6  [Train, Test]   \n",
      "6          0         0           0      7  [Train, Test]   \n",
      "7          0         0           0      8  [Train, Test]   \n",
      "8          0         0           0      9  [Train, Test]   \n",
      "9          0         0           0     10  [Train, Test]   \n",
      "10         0         0           1      1  [Train, Test]   \n",
      "11         0         0           1      2  [Train, Test]   \n",
      "12         0         0           1      3  [Train, Test]   \n",
      "13         0         0           1      4  [Train, Test]   \n",
      "14         0         0           1      5  [Train, Test]   \n",
      "15         0         0           1      6  [Train, Test]   \n",
      "16         0         0           1      7  [Train, Test]   \n",
      "17         0         0           1      8  [Train, Test]   \n",
      "18         0         0           1      9  [Train, Test]   \n",
      "19         0         0           1     10  [Train, Test]   \n",
      "20         0         1           0      1  [Train, Test]   \n",
      "21         0         1           0      2  [Train, Test]   \n",
      "22         0         1           0      3  [Train, Test]   \n",
      "23         0         1           0      4  [Train, Test]   \n",
      "24         0         1           0      5  [Train, Test]   \n",
      "25         0         1           0      6  [Train, Test]   \n",
      "26         0         1           0      7  [Train, Test]   \n",
      "27         0         1           0      8  [Train, Test]   \n",
      "28         0         1           0      9  [Train, Test]   \n",
      "29         0         1           0     10  [Train, Test]   \n",
      "30         1         0           0      1  [Train, Test]   \n",
      "31         1         0           0      2  [Train, Test]   \n",
      "32         1         0           0      3  [Train, Test]   \n",
      "33         1         0           0      4  [Train, Test]   \n",
      "34         1         0           0      5  [Train, Test]   \n",
      "35         1         0           0      6  [Train, Test]   \n",
      "36         1         0           0      7  [Train, Test]   \n",
      "37         1         0           0      8  [Train, Test]   \n",
      "38         1         0           0      9  [Train, Test]   \n",
      "39         1         0           0     10  [Train, Test]   \n",
      "40         1         0           1      1  [Train, Test]   \n",
      "41         1         0           1      2  [Train, Test]   \n",
      "42         1         0           1      3  [Train, Test]   \n",
      "43         1         0           1      4  [Train, Test]   \n",
      "44         1         0           1      5  [Train, Test]   \n",
      "45         1         0           1      6  [Train, Test]   \n",
      "46         1         0           1      7  [Train, Test]   \n",
      "47         1         0           1      8  [Train, Test]   \n",
      "48         1         0           1      9  [Train, Test]   \n",
      "49         1         0           1     10  [Train, Test]   \n",
      "\n",
      "                               Accuracy (%)  \\\n",
      "0    [47.99516908212561, 47.21126760563381]   \n",
      "1    [47.99516908212561, 47.21126760563381]   \n",
      "2    [47.99516908212561, 47.21126760563381]   \n",
      "3    [47.99516908212561, 47.21126760563381]   \n",
      "4    [47.99516908212561, 47.21126760563381]   \n",
      "5    [47.99516908212561, 47.21126760563381]   \n",
      "6    [47.99516908212561, 47.21126760563381]   \n",
      "7    [47.99516908212561, 47.21126760563381]   \n",
      "8    [47.99516908212561, 47.21126760563381]   \n",
      "9    [47.99516908212561, 47.21126760563381]   \n",
      "10   [47.99516908212561, 47.21126760563381]   \n",
      "11   [47.99516908212561, 47.21126760563381]   \n",
      "12   [47.99516908212561, 47.21126760563381]   \n",
      "13   [47.99516908212561, 47.21126760563381]   \n",
      "14   [47.99516908212561, 47.21126760563381]   \n",
      "15   [47.99516908212561, 47.21126760563381]   \n",
      "16   [47.99516908212561, 47.21126760563381]   \n",
      "17   [47.99516908212561, 47.21126760563381]   \n",
      "18   [47.99516908212561, 47.21126760563381]   \n",
      "19   [47.99516908212561, 47.21126760563381]   \n",
      "20  [48.28502415458937, 47.774647887323944]   \n",
      "21  [48.28502415458937, 47.774647887323944]   \n",
      "22  [48.28502415458937, 47.774647887323944]   \n",
      "23  [48.28502415458937, 47.774647887323944]   \n",
      "24  [48.28502415458937, 47.774647887323944]   \n",
      "25  [48.28502415458937, 47.774647887323944]   \n",
      "26  [48.28502415458937, 47.774647887323944]   \n",
      "27  [48.28502415458937, 47.774647887323944]   \n",
      "28  [48.28502415458937, 47.774647887323944]   \n",
      "29  [48.28502415458937, 47.774647887323944]   \n",
      "30  [47.94685990338164, 47.267605633802816]   \n",
      "31  [47.94685990338164, 47.267605633802816]   \n",
      "32  [47.94685990338164, 47.267605633802816]   \n",
      "33  [47.94685990338164, 47.267605633802816]   \n",
      "34  [47.94685990338164, 47.267605633802816]   \n",
      "35  [47.94685990338164, 47.267605633802816]   \n",
      "36  [47.94685990338164, 47.267605633802816]   \n",
      "37  [47.94685990338164, 47.267605633802816]   \n",
      "38  [47.94685990338164, 47.267605633802816]   \n",
      "39  [47.94685990338164, 47.267605633802816]   \n",
      "40  [47.94685990338164, 47.267605633802816]   \n",
      "41  [47.94685990338164, 47.267605633802816]   \n",
      "42  [47.94685990338164, 47.267605633802816]   \n",
      "43  [47.94685990338164, 47.267605633802816]   \n",
      "44  [47.94685990338164, 47.267605633802816]   \n",
      "45  [47.94685990338164, 47.267605633802816]   \n",
      "46  [47.94685990338164, 47.267605633802816]   \n",
      "47  [47.94685990338164, 47.267605633802816]   \n",
      "48  [47.94685990338164, 47.267605633802816]   \n",
      "49  [47.94685990338164, 47.267605633802816]   \n",
      "\n",
      "                                P-rule (%)  \\\n",
      "0   [99.96170184400773, 99.90671641791045]   \n",
      "1   [99.96170184400773, 99.90671641791045]   \n",
      "2   [99.96170184400773, 99.90671641791045]   \n",
      "3   [99.96170184400773, 99.90671641791045]   \n",
      "4   [99.96170184400773, 99.90671641791045]   \n",
      "5   [99.96170184400773, 99.90671641791045]   \n",
      "6   [99.96170184400773, 99.90671641791045]   \n",
      "7   [99.96170184400773, 99.90671641791045]   \n",
      "8   [99.96170184400773, 99.90671641791045]   \n",
      "9   [99.96170184400773, 99.90671641791045]   \n",
      "10  [99.96170184400773, 99.90671641791045]   \n",
      "11  [99.96170184400773, 99.90671641791045]   \n",
      "12  [99.96170184400773, 99.90671641791045]   \n",
      "13  [99.96170184400773, 99.90671641791045]   \n",
      "14  [99.96170184400773, 99.90671641791045]   \n",
      "15  [99.96170184400773, 99.90671641791045]   \n",
      "16  [99.96170184400773, 99.90671641791045]   \n",
      "17  [99.96170184400773, 99.90671641791045]   \n",
      "18  [99.96170184400773, 99.90671641791045]   \n",
      "19  [99.96170184400773, 99.90671641791045]   \n",
      "20  [99.92629445365763, 99.26135998629522]   \n",
      "21  [99.92629445365763, 99.26135998629522]   \n",
      "22  [99.92629445365763, 99.26135998629522]   \n",
      "23  [99.92629445365763, 99.26135998629522]   \n",
      "24  [99.92629445365763, 99.26135998629522]   \n",
      "25  [99.92629445365763, 99.26135998629522]   \n",
      "26  [99.92629445365763, 99.26135998629522]   \n",
      "27  [99.92629445365763, 99.26135998629522]   \n",
      "28  [99.92629445365763, 99.26135998629522]   \n",
      "29  [99.92629445365763, 99.26135998629522]   \n",
      "30  [99.94252943244784, 99.95099035346713]   \n",
      "31  [99.94252943244784, 99.95099035346713]   \n",
      "32  [99.94252943244784, 99.95099035346713]   \n",
      "33  [99.94252943244784, 99.95099035346713]   \n",
      "34  [99.94252943244784, 99.95099035346713]   \n",
      "35  [99.94252943244784, 99.95099035346713]   \n",
      "36  [99.94252943244784, 99.95099035346713]   \n",
      "37  [99.94252943244784, 99.95099035346713]   \n",
      "38  [99.94252943244784, 99.95099035346713]   \n",
      "39  [99.94252943244784, 99.95099035346713]   \n",
      "40  [99.94252943244784, 99.95099035346713]   \n",
      "41  [99.94252943244784, 99.95099035346713]   \n",
      "42  [99.94252943244784, 99.95099035346713]   \n",
      "43  [99.94252943244784, 99.95099035346713]   \n",
      "44  [99.94252943244784, 99.95099035346713]   \n",
      "45  [99.94252943244784, 99.95099035346713]   \n",
      "46  [99.94252943244784, 99.95099035346713]   \n",
      "47  [99.94252943244784, 99.95099035346713]   \n",
      "48  [99.94252943244784, 99.95099035346713]   \n",
      "49  [99.94252943244784, 99.95099035346713]   \n",
      "\n",
      "                             Protected (%)  \\\n",
      "0               [99.88059701492537, 100.0]   \n",
      "1               [99.88059701492537, 100.0]   \n",
      "2               [99.88059701492537, 100.0]   \n",
      "3               [99.88059701492537, 100.0]   \n",
      "4               [99.88059701492537, 100.0]   \n",
      "5               [99.88059701492537, 100.0]   \n",
      "6               [99.88059701492537, 100.0]   \n",
      "7               [99.88059701492537, 100.0]   \n",
      "8               [99.88059701492537, 100.0]   \n",
      "9               [99.88059701492537, 100.0]   \n",
      "10              [99.88059701492537, 100.0]   \n",
      "11              [99.88059701492537, 100.0]   \n",
      "12              [99.88059701492537, 100.0]   \n",
      "13              [99.88059701492537, 100.0]   \n",
      "14              [99.88059701492537, 100.0]   \n",
      "15              [99.88059701492537, 100.0]   \n",
      "16              [99.88059701492537, 100.0]   \n",
      "17              [99.88059701492537, 100.0]   \n",
      "18              [99.88059701492537, 100.0]   \n",
      "19              [99.88059701492537, 100.0]   \n",
      "20  [98.50746268656717, 99.14651493598862]   \n",
      "21  [98.50746268656717, 99.14651493598862]   \n",
      "22  [98.50746268656717, 99.14651493598862]   \n",
      "23  [98.50746268656717, 99.14651493598862]   \n",
      "24  [98.50746268656717, 99.14651493598862]   \n",
      "25  [98.50746268656717, 99.14651493598862]   \n",
      "26  [98.50746268656717, 99.14651493598862]   \n",
      "27  [98.50746268656717, 99.14651493598862]   \n",
      "28  [98.50746268656717, 99.14651493598862]   \n",
      "29  [98.50746268656717, 99.14651493598862]   \n",
      "30  [99.82089552238807, 99.85775248933145]   \n",
      "31  [99.82089552238807, 99.85775248933145]   \n",
      "32  [99.82089552238807, 99.85775248933145]   \n",
      "33  [99.82089552238807, 99.85775248933145]   \n",
      "34  [99.82089552238807, 99.85775248933145]   \n",
      "35  [99.82089552238807, 99.85775248933145]   \n",
      "36  [99.82089552238807, 99.85775248933145]   \n",
      "37  [99.82089552238807, 99.85775248933145]   \n",
      "38  [99.82089552238807, 99.85775248933145]   \n",
      "39  [99.82089552238807, 99.85775248933145]   \n",
      "40  [99.82089552238807, 99.85775248933145]   \n",
      "41  [99.82089552238807, 99.85775248933145]   \n",
      "42  [99.82089552238807, 99.85775248933145]   \n",
      "43  [99.82089552238807, 99.85775248933145]   \n",
      "44  [99.82089552238807, 99.85775248933145]   \n",
      "45  [99.82089552238807, 99.85775248933145]   \n",
      "46  [99.82089552238807, 99.85775248933145]   \n",
      "47  [99.82089552238807, 99.85775248933145]   \n",
      "48  [99.82089552238807, 99.85775248933145]   \n",
      "49  [99.82089552238807, 99.85775248933145]   \n",
      "\n",
      "                         Not protected (%)  \\\n",
      "0   [99.91886409736308, 99.90671641791045]   \n",
      "1   [99.91886409736308, 99.90671641791045]   \n",
      "2   [99.91886409736308, 99.90671641791045]   \n",
      "3   [99.91886409736308, 99.90671641791045]   \n",
      "4   [99.91886409736308, 99.90671641791045]   \n",
      "5   [99.91886409736308, 99.90671641791045]   \n",
      "6   [99.91886409736308, 99.90671641791045]   \n",
      "7   [99.91886409736308, 99.90671641791045]   \n",
      "8   [99.91886409736308, 99.90671641791045]   \n",
      "9   [99.91886409736308, 99.90671641791045]   \n",
      "10  [99.91886409736308, 99.90671641791045]   \n",
      "11  [99.91886409736308, 99.90671641791045]   \n",
      "12  [99.91886409736308, 99.90671641791045]   \n",
      "13  [99.91886409736308, 99.90671641791045]   \n",
      "14  [99.91886409736308, 99.90671641791045]   \n",
      "15  [99.91886409736308, 99.90671641791045]   \n",
      "16  [99.91886409736308, 99.90671641791045]   \n",
      "17  [99.91886409736308, 99.90671641791045]   \n",
      "18  [99.91886409736308, 99.90671641791045]   \n",
      "19  [99.91886409736308, 99.90671641791045]   \n",
      "20  [98.58012170385395, 98.41417910447761]   \n",
      "21  [98.58012170385395, 98.41417910447761]   \n",
      "22  [98.58012170385395, 98.41417910447761]   \n",
      "23  [98.58012170385395, 98.41417910447761]   \n",
      "24  [98.58012170385395, 98.41417910447761]   \n",
      "25  [98.58012170385395, 98.41417910447761]   \n",
      "26  [98.58012170385395, 98.41417910447761]   \n",
      "27  [98.58012170385395, 98.41417910447761]   \n",
      "28  [98.58012170385395, 98.41417910447761]   \n",
      "29  [98.58012170385395, 98.41417910447761]   \n",
      "30  [99.87829614604462, 99.90671641791045]   \n",
      "31  [99.87829614604462, 99.90671641791045]   \n",
      "32  [99.87829614604462, 99.90671641791045]   \n",
      "33  [99.87829614604462, 99.90671641791045]   \n",
      "34  [99.87829614604462, 99.90671641791045]   \n",
      "35  [99.87829614604462, 99.90671641791045]   \n",
      "36  [99.87829614604462, 99.90671641791045]   \n",
      "37  [99.87829614604462, 99.90671641791045]   \n",
      "38  [99.87829614604462, 99.90671641791045]   \n",
      "39  [99.87829614604462, 99.90671641791045]   \n",
      "40  [99.87829614604462, 99.90671641791045]   \n",
      "41  [99.87829614604462, 99.90671641791045]   \n",
      "42  [99.87829614604462, 99.90671641791045]   \n",
      "43  [99.87829614604462, 99.90671641791045]   \n",
      "44  [99.87829614604462, 99.90671641791045]   \n",
      "45  [99.87829614604462, 99.90671641791045]   \n",
      "46  [99.87829614604462, 99.90671641791045]   \n",
      "47  [99.87829614604462, 99.90671641791045]   \n",
      "48  [99.87829614604462, 99.90671641791045]   \n",
      "49  [99.87829614604462, 99.90671641791045]   \n",
      "\n",
      "                             Calibration (%)  \n",
      "0   [11.623141897005846, 14.813777839111697]  \n",
      "1   [11.623141897005846, 14.813777839111697]  \n",
      "2   [11.623141897005846, 14.813777839111697]  \n",
      "3   [11.623141897005846, 14.813777839111697]  \n",
      "4   [11.623141897005846, 14.813777839111697]  \n",
      "5   [11.623141897005846, 14.813777839111697]  \n",
      "6   [11.623141897005846, 14.813777839111697]  \n",
      "7   [11.623141897005846, 14.813777839111697]  \n",
      "8   [11.623141897005846, 14.813777839111697]  \n",
      "9   [11.623141897005846, 14.813777839111697]  \n",
      "10  [11.623141897005846, 14.813777839111697]  \n",
      "11  [11.623141897005846, 14.813777839111697]  \n",
      "12  [11.623141897005846, 14.813777839111697]  \n",
      "13  [11.623141897005846, 14.813777839111697]  \n",
      "14  [11.623141897005846, 14.813777839111697]  \n",
      "15  [11.623141897005846, 14.813777839111697]  \n",
      "16  [11.623141897005846, 14.813777839111697]  \n",
      "17  [11.623141897005846, 14.813777839111697]  \n",
      "18  [11.623141897005846, 14.813777839111697]  \n",
      "19  [11.623141897005846, 14.813777839111697]  \n",
      "20   [11.40807120583694, 14.804489288974754]  \n",
      "21   [11.40807120583694, 14.804489288974754]  \n",
      "22   [11.40807120583694, 14.804489288974754]  \n",
      "23   [11.40807120583694, 14.804489288974754]  \n",
      "24   [11.40807120583694, 14.804489288974754]  \n",
      "25   [11.40807120583694, 14.804489288974754]  \n",
      "26   [11.40807120583694, 14.804489288974754]  \n",
      "27   [11.40807120583694, 14.804489288974754]  \n",
      "28   [11.40807120583694, 14.804489288974754]  \n",
      "29   [11.40807120583694, 14.804489288974754]  \n",
      "30  [11.642275438224697, 15.142592513959368]  \n",
      "31  [11.642275438224697, 15.142592513959368]  \n",
      "32  [11.642275438224697, 15.142592513959368]  \n",
      "33  [11.642275438224697, 15.142592513959368]  \n",
      "34  [11.642275438224697, 15.142592513959368]  \n",
      "35  [11.642275438224697, 15.142592513959368]  \n",
      "36  [11.642275438224697, 15.142592513959368]  \n",
      "37  [11.642275438224697, 15.142592513959368]  \n",
      "38  [11.642275438224697, 15.142592513959368]  \n",
      "39  [11.642275438224697, 15.142592513959368]  \n",
      "40  [11.642275438224697, 15.142592513959368]  \n",
      "41  [11.642275438224697, 15.142592513959368]  \n",
      "42  [11.642275438224697, 15.142592513959368]  \n",
      "43  [11.642275438224697, 15.142592513959368]  \n",
      "44  [11.642275438224697, 15.142592513959368]  \n",
      "45  [11.642275438224697, 15.142592513959368]  \n",
      "46  [11.642275438224697, 15.142592513959368]  \n",
      "47  [11.642275438224697, 15.142592513959368]  \n",
      "48  [11.642275438224697, 15.142592513959368]  \n",
      "49  [11.642275438224697, 15.142592513959368]  \n"
     ]
    }
   ],
   "source": [
    "# Iterate through different constraints and their combinations\n",
    "results_list = []\n",
    "\n",
    "for fairness_constraint in [0, 1]:\n",
    "    for accuracy_constraint in [0, 1]:\n",
    "        for separate_constraint in [0, 1]:\n",
    "            if accuracy_constraint + separate_constraint <= 1 and not (fairness_constraint == 1 and accuracy_constraint == 1):\n",
    "                # Iterate through different gamma values\n",
    "                for gamma in np.arange(1, 11, 1):\n",
    "\n",
    "                    # Train model with constraints\n",
    "                    np.random.seed(704)\n",
    "                    cweight = ut.train_model(x_train,\n",
    "                                             y_train,\n",
    "                                             x_control,\n",
    "                                             lf._logistic_loss,\n",
    "                                             fairness_constraint,\n",
    "                                             accuracy_constraint,\n",
    "                                             separate_constraint,\n",
    "                                             sensitive_attrs,\n",
    "                                             sensitive_attrs_to_cov_thresh,\n",
    "                                             gamma)\n",
    "\n",
    "                    # Fit coefficients/weights into logistic regression in sklearn\n",
    "                    m = LogisticRegression()\n",
    "                    m.coef_ = cweight.reshape((1, -1))\n",
    "                    m.intercept_ = 0\n",
    "                    m.classes_ = np.array([0, 1])\n",
    "\n",
    "                    # Evaluate the results\n",
    "                    result = {\"Fairness\": fairness_constraint,\n",
    "                              \"Accuracy\": accuracy_constraint,\n",
    "                              \"Separation\": separate_constraint,\n",
    "                              \"Gamma\": gamma,\n",
    "                              \"Set\": [\"Train\", \"Test\"],\n",
    "                              \"Accuracy (%)\": [m.score(x_train, y_train) * 100, m.score(x_test, y_test) * 100],\n",
    "                              \"P-rule (%)\": [p_rule(race_train, m.predict(x_train))[0] * 100, p_rule(race_test, m.predict(x_test))[0] * 100],\n",
    "                              \"Protected (%)\": [p_rule(race_train, m.predict(x_train))[1] * 100, p_rule(race_test, m.predict(x_test))[1] * 100],\n",
    "                              \"Not protected (%)\": [p_rule(race_train, m.predict(x_train))[2] * 100, p_rule(race_test, m.predict(x_test))[2] * 100],\n",
    "                              \"Calibration (%)\": [calibration(race_train, m.predict(x_train), y_train) * 100, calibration(race_test, m.predict(x_test), y_test) * 100]}\n",
    "                    \n",
    "                    results_list.append(result)\n",
    "\n",
    "# Print the results\n",
    "results_df = pd.DataFrame(results_list)\n",
    "results_df = results_df[[\"Fairness\", \"Accuracy\", \"Separation\", \"Gamma\", \"Set\", \"Accuracy (%)\", \"P-rule (%)\", \"Protected (%)\", \"Not protected (%)\", \"Calibration (%)\"]]\n",
    "print(results_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
